{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A homework on mulitway fixed effect approach\n",
    "\n",
    "In this homework we are going to consider a fictuous grading at a given universities and try to see what we can learn from grade variability and it affects earnings.\n",
    "\n",
    "In the first data set we have the grades collected by a bunch of student within a given summester. Each student attended 3 courses. From this data we are going to try to extrac the ability of each student while allowing for course specific intercept. We can then use this to evaluate how much of the grade variation is due to student differences versus course differences and other factors (residuals). \n",
    "\n",
    "Given this ability measures, we then merge a second file which has the earnings of the student at age 35. We then evaluate the effect of academic ability on individual earnings. Here again we will worry about the effect of over-fitting.\n",
    "\n",
    "Of course this requires, like we saw in class, estimating many parameters, hence we will look into overfitting and how to address it! We wil lmake use of sparse matrices, degree of freedom correction and bias correction.\n",
    "\n",
    "The two data files you will need are:\n",
    "\n",
    " - grades: [hw4-grades.json](http://econ21340.lamadon.com/hw4-grades.json)\n",
    " - earnings: [hw4-earnings.json](http://econ21340.lamadon.com/hw4-earnings.json)\n",
    "\n",
    "Useful links:\n",
    " - [Sparse linear solver](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.spsolve.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T19:00:10.080631Z",
     "start_time": "2020-05-29T19:00:08.915525Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T19:00:10.800282Z",
     "start_time": "2020-05-29T19:00:10.723044Z"
    }
   },
   "outputs": [],
   "source": [
    "# %cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# import solutions.sol_pset4 as solution # you need to command this, you don't have the solution file!\n",
    "#solution.simulate_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining the dispersion in grades\n",
    "\n",
    "Load the grade data from `hw4-grades.json`. Then compute:\n",
    "\n",
    " 1. total variance in grades\n",
    " 2. the between class variance\n",
    " 3. plot the histogram of class size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_path = \"data/hw4-grades.json\"\n",
    "earnings_path = \"data/hw4-earnings.json\"\n",
    "df_grades = pd.read_json(grade_path, lines=True,\n",
    "                          dtype={'grade':int,\n",
    "                                 'class_id':str,\n",
    "                                 'student_id':str,\n",
    "                                 'major':int,\n",
    "                                 'firstname':str})\n",
    "df_earnings = pd.read_json(earnings_path, lines = True,\n",
    "                          dtype={'student_id':str,\n",
    "                                 'major':str,\n",
    "                                 'firstname':str,\n",
    "                                 'earnings':int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question1(df):\n",
    "    grade_var = np.var(df_grades[\"grade\"])\n",
    "    print(\"total variance in grades: {}\".format(grade_var))\n",
    "    class_tab = df_grades.groupby(\"class_id\").agg(size = pd.NamedAgg(column='student_id', aggfunc='count'),\n",
    "                                           mean_grade = pd.NamedAgg(column = \"grade\", aggfunc = \"mean\"),\n",
    "                                             var_grade = pd.NamedAgg(column = \"grade\", aggfunc = \"var\"))\n",
    "    class_var = np.var(class_tab[\"mean_grade\"])\n",
    "    print(\"between class variance: {}\".format(class_var))\n",
    "    plt.figure()\n",
    "    plt.hist(class_tab[\"size\"])\n",
    "    plt.xlabel(\"Class Size\")\n",
    "    plt.ylabel(\"Number of Classes\")\n",
    "    plt.title(\"Histogram of Class Sizes\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T20:47:25.191869Z",
     "start_time": "2020-05-29T20:47:24.871739Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variance in grades: 1.347032719059103\n",
      "between class variance: 0.3604792888212968\n",
      "6515 students and 673 classes\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_all = question1(df_grades)\n",
    "# df_all = solution.question1()\n",
    "\n",
    "ns = len(np.unique(df_all['student_id']))\n",
    "nc = len(np.unique(df_all['class_id']))\n",
    "nn = len(df_all)\n",
    "\n",
    "print(\"{} students and {} classes\".format(ns,nc))\n",
    "\n",
    "# df_all[[\"grade\",\"class_id\",\"student_id\",\"major\",\"firstname\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the sparse regressor matrices\n",
    "\n",
    "In a similar fashion to what we covered in the class we want to estimate a two-way fixed model of grates. Specifically, we are want to fit:\n",
    "\n",
    "$$y_{ic} = \\alpha_i + \\psi_c + \\epsilon_{ic}$$ \n",
    "\n",
    "where $i$ denotes each individual, $c$ denote each courses and $\\epsilon_{ic}$ is an error term that will assume conditional mean independent of the assignment of students to courses.\n",
    "\n",
    "We are going to estimate this using least-square. This requires that we construct the matrices that correspond to the equation for $y_{ic}$. We then want to consruct the $A$ and $J$ such that \n",
    "\n",
    "$$Y = A \\alpha + J \\psi + E$$ \n",
    "\n",
    "where for $n_s$ students each with $n_g$ grades in difference courses and a total of $n_c$ courses we have that $Y$ is $n_s \\cdot n_g \\times 1$ vector, $A$ is a $n_s \\cdot n_g \\times n_s$ matrix and $J$ is $n_s \\cdot n_g \\times n_c$. $\\alpha$ is the vector of size $n_s$ and $\\psi$ is a vector of size $n_c$.\n",
    "\n",
    "Each fo the $n_s \\cdot n_g$ correspond to a grade, in each row $A$ has a $1$ in the column corresponding to the individual of this row. Similary, $J$ has a $1$ for for the column corresponding to the class of that row.\n",
    "\n",
    "So, I ask you to:\n",
    "\n",
    " 1. construct these matrices using python sparse matrices `scipy.sparse.csc.csc_matrix`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T20:47:32.946282Z",
     "start_time": "2020-05-29T20:47:32.516687Z"
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 669. MiB for an array with shape (13464, 6515) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-74b2606f48b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJ\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquestion2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-74b2606f48b7>\u001b[0m in \u001b[0;36mquestion2\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mstudent_inv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mu\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mstudent_onehot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstudent_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"student_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsc_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudent_onehot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;31m#     A = pd.get_dummies(df[\"class_id\"])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vanessa\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1023\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1025\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1026\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vanessa\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1187\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1189\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 669. MiB for an array with shape (13464, 6515) and data type float64"
     ]
    }
   ],
   "source": [
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.sparse import csc_matrix\n",
    "# Y,A,J = solution.question2(df_all)\n",
    "def question2(df):\n",
    "    # CREATE Y MATRIX\n",
    "#     Y = np.zeros(nn, 1) # all records x 1\n",
    "    Y = csc_matrix((df[\"grade\"], (np.arange(nn), np.zeros(nn))), shape = (nn, 1)).toarray()\n",
    "#     Y = df[\"grade\"].to_numpy()\n",
    "\n",
    "    # CREATE A MATRIX\n",
    "#     A = np.zeros(nn, ns) # all records x ns\n",
    "    students = np.unique(df_all[\"student_id\"])\n",
    "    student_map = {u:i for i, u in enumerate(students)}\n",
    "    student_inv = {i:u for i, u in enumerate(students)}\n",
    "    student_onehot = [student_map[i] for i in df[\"student_id\"]]\n",
    "    A = csc_matrix((np.ones(nn), (np.arange(nn), student_onehot)), shape = (nn, ns)).toarray()\n",
    "#     A = pd.get_dummies(df[\"class_id\"])\n",
    "\n",
    "    # CREATE J MATRIX\n",
    "#     J = np.zeros(nn, nc) # all records x nc\n",
    "    classes = np.unique(df_all[\"class_id\"])\n",
    "    class_map = {u:i for i, u in enumerate(classes)}\n",
    "    class_inv = {i:u for i, u in enumerate(classes)}\n",
    "    class_onehot = [class_map[i] for i in df[\"class_id\"]]\n",
    "    J = csc_matrix((np.ones(nn), (np.arange(nn), class_onehot)), shape = (nn, nc)).toarray()\n",
    "    \n",
    "    return Y, A, J\n",
    "\n",
    "Y, A, J = question2(df_all)\n",
    "print(type(A))\n",
    "print(A.shape)\n",
    "print(J.shape)\n",
    "print(Y.shape)\n",
    "print(A.sum())\n",
    "print(J.sum())\n",
    "\n",
    "# getting a nice diagonal here requires sorting by the studend_id\n",
    "plt.spy(A,aspect=0.1,markersize=0.2)\n",
    "plt.show()\n",
    "plt.spy(J,aspect=0.1,markersize=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating the model\n",
    "\n",
    "Next we estimate our model using the OLS estiamtor formula. We first remove the last column of $J$ (since the model we wrote does not pin down a constant we force the last course to have $\\psi=0$). Solve the linear system using the formula\n",
    "\n",
    "$$ \\hat{\\gamma} = (M'M)^{-1} M' Y $$\n",
    "\n",
    "where $M = [A,J]$ and $\\gamma = (\\alpha,\\psi)$.\n",
    "\n",
    "So do the following:\n",
    "\n",
    " 1. select the last column simply by doing `J = J[:,1:(nc-1]]`\n",
    " 2. use `scipy.sparse.hstack` to concatenate the matrices to create M\n",
    " 3. use `scipy.sparse.linalg.spsolve` to solve a sparse linear system\n",
    " 4. extract $\\hat{\\alpha}$ from $\\hat{\\gamma}$ by selecting the first $n_s$ terms \n",
    " 5. merge $\\hat{\\alpha}$ into `df_all`\n",
    " 6. compute the variance of $\\hat{\\alpha}$ in `df_all`\n",
    " 7. compute the variance of the residuals\n",
    " 8. What share of the total variation in grades can be attributed to difference in students?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T21:36:46.166385Z",
     "start_time": "2020-05-29T21:36:41.741158Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all, M, gamma_hat = solution.question3(df_all,A,J,Y)\n",
    "print(df_all['alpha_hat'].var(),df_all['resid'].var(),df_all['grade'].var(),df_all['A'].var())\n",
    "df_all[[\"grade\",\"class_id\",\"student_id\",\"major\",\"firstname\",\"alpha_hat\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple evaluation of our estimator\n",
    "\n",
    "To see what we are dealing with, we are simly going to re-simulate using our estimated parameters, then re-run our estimation and compare the new results to the previous one. This is in the spirit of a bootstrap exercise, onyl we will just do it once this time.\n",
    "\n",
    "Please do:\n",
    "\n",
    " 1. create $Y_2 = M \\hat{\\gamma} + \\hat{\\sigma}_r E$ where $E$ is a vector of draw from a standard normal.\n",
    " 2. estimate $\\hat{\\gamma}_2$ from $Y_2$\n",
    " 3. report the new variance term and compare them to the previously estimated\n",
    " 4. comment on the results (not that because of the seed and ordering, your number doesn't have to match mine exactly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T21:08:46.590613Z",
     "start_time": "2020-05-29T21:08:42.577398Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all = solution.question4(df_all,M,gamma_hat)\n",
    "df_all['alpha_hat2'].var(),df_all['resid2'].var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noticed how even the variance of the residual has shrunk? Now is the time to remember STATS 101. We have all heard this thing about degree of freedom correction! Indeed we should correct our raw variance estimates to control for the fact that we have estimated a bunhc of dummies. Usually we use $n/n-1$ because we only estimate one mean. Here however we have estimated $n_s +n_c - 1$ means! Hence we should use \n",
    "\n",
    "$$ \\frac{N}{N-n_s -n_c +1} \\hat{Var}(\\hat{\\epsilon}) $$\n",
    "\n",
    "please do:\n",
    "\n",
    " 1. compute this variance corrected for degree of freedom using your recomputed residuals \n",
    " 2. compare this variance to the variance you estimated in quetion 3\n",
    " 3. what does this suggest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T21:49:40.960930Z",
     "start_time": "2020-05-29T21:49:40.879416Z"
    }
   },
   "outputs": [],
   "source": [
    "solution.question4b(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate impact of academic measure on earnings \n",
    "\n",
    "In this section we load a separate data set that contains for each student their earnings at age 35. We are intereted in the effect of $\\alpha$ on earnings. \n",
    "\n",
    "Do the following:\n",
    "\n",
    " 1. load the data the earnings data listed in the intro\n",
    " 2. merge $\\alpha$ into the data\n",
    " 3. regress earnings on $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T21:24:02.382987Z",
     "start_time": "2020-05-29T21:24:02.216161Z"
    }
   },
   "outputs": [],
   "source": [
    "df_earnings = solution.question5(df_all)\n",
    "df_earnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias correction - construct the Q matrix\n",
    "\n",
    "We want to apply bias correction to refine our results. As we have seen in class thaqt we can directly compute the bias of the expression of interest.\n",
    "\n",
    "$$ E[ \\hat{\\gamma} Q \\hat{\\gamma}' ] = \\gamma Q \\gamma + \\frac{\\sigma^2}{n} \\text{Tr}[ ( M'M )^{-1} Q] $$\n",
    "\n",
    "under homoskedatic assumption of the error and hence we get the following expresison for the bias for any $Q$ matrix:\n",
    "\n",
    "$$ B = \\frac{\\sigma^2}{N} \\text{Tr}[ ( M'M )^{-1} Q] $$\n",
    "\n",
    "When computing the variance of the measured ability of the student, we simply use a diagonal matrix on $\\gamma$ which selects only the ability part and removes the average. In other words we want to construct:\n",
    "\n",
    "do:\n",
    " 1. Construct such Q matrix.\n",
    " 2. check that $\\gamma Q \\gamma' = \\hat{Var}(\\hat{a})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T21:38:31.470861Z",
     "start_time": "2020-05-29T21:38:30.625410Z"
    }
   },
   "outputs": [],
   "source": [
    "# a small example if we had ns=5,nc=4\n",
    "Qbis = solution.question6(ns=5,nc=4)\n",
    "print(Qbis)\n",
    "\n",
    "# the full Q\n",
    "Q = solution.question6(ns,nc)\n",
    "\n",
    "# comparing Q expression to df_all expression\n",
    "1/(ns)*np.matmul( gamma_hat, np.matmul(Q,gamma_hat )), gamma_hat[range(ns)].var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias correction - Variance sahre\n",
    "\n",
    "We are now finally in the position to compute our bias. We have are matrix $Q$. Now we also need the variance of the residual! Given what we have learn in Question 4, we definitely want to use the formula with degree of freedom correction.\n",
    "\n",
    "1. Compute $\\sigma^2_r$ with the degree of freedom correction\n",
    "2. Invert $M'M$ using `scipy.sparse.linalg`\n",
    "3. Compute $B = \\frac{\\sigma^2}{N} \\text{Tr}[ ( M'M )^{-1} Q]$ using `np.trace`\n",
    "4. Remove this from original estimate to get the share of variance explained by student differences!\n",
    "\n",
    "Note that inversing a matrix is far longer than solving a linear system. You might need to be patient here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T22:03:04.700325Z",
     "start_time": "2020-05-29T22:01:26.849096Z"
    }
   },
   "outputs": [],
   "source": [
    "B = solution.question7(M,Q,df_all)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T22:03:10.688151Z",
     "start_time": "2020-05-29T22:03:10.635514Z"
    }
   },
   "outputs": [],
   "source": [
    "gamma_hat[range(ns)].var() - B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias correction - Regression coefficient\n",
    "\n",
    "Finally, we look back at our regression of earnings on estimated academic ability. We have seen in class that when the regressor has measurment error this will suffer from attenuation bias. Here we now know exactly how much of the variance is noise thanks to our bias correction.\n",
    "\n",
    "The attenuation bias is given by :\n",
    "\n",
    "$$ \\beta_2 = \\frac{Var(x)}{Var(x) + B} \\beta $$\n",
    "\n",
    "We then decide to compute a correction for our regression using our estimated $B$. \n",
    "\n",
    "Do:\n",
    "\n",
    " 1. compute the corrected beta\n",
    " 2. FIY, the true $\\beta$ I used to simulate the data was **2.0**, is your final parameter far? Is is economically different from the $\\beta$ we got in Question 5?\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "I hope you have learned about the pitfalls of over-fitting in this assignment! There are many and they can drastically affect the results and the conclusion of an empirical analysis. \n",
    "\n",
    "This is the end of the class, I hope you enjoyed it and that you learned a thing or twom, have a nice summer!"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
